{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ì²˜ìŒë¶€í„° ReAct ì—ì´ì „íŠ¸ë¥¼ ë§Œë“œëŠ” ë°©ë²•\n\n!!! info \"í•„ìˆ˜ ì¡°ê±´\"\n    ì´ ê°€ì´ë“œëŠ” ë‹¤ìŒì— ëŒ€í•œ ìµìˆ™í•¨ì„ ê°€ì •í•©ë‹ˆë‹¤:\n    \n    - [ë„êµ¬ í˜¸ì¶œ ì—ì´ì „íŠ¸](../../concepts/agentic_concepts/#tool-calling-agent)\n    - [ì±„íŒ… ëª¨ë¸](https://python.langchain.com/docs/concepts/chat_models/)\n    - [ë©”ì‹œì§€](https://python.langchain.com/docs/concepts/messages/)\n    - [LangGraph ìš©ì–´ì§‘](../../concepts/low_level/)\n\nì‚¬ì „ êµ¬ì¶•ëœ ReAct ì—ì´ì „íŠ¸ [create_react_agent][langgraph.prebuilt.chat_agent_executor.create_react_agent]ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ì‹œì‘í•˜ê¸°ì— ì¢‹ì€ ë°©ë²•ì´ì§€ë§Œ, ë•Œë¡œëŠ” ë” ë§ì€ ì œì–´ì™€ ì‚¬ìš©ì ì •ì˜ë¥¼ ì›í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²½ìš° ì‚¬ìš©ì ì •ì˜ ReAct ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê°€ì´ë“œëŠ” LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ìŒë¶€í„° ReAct ì—ì´ì „íŠ¸ë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\n## ì„¤ì •\n\në¨¼ì € í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  API í‚¤ë¥¼ ì„¤ì •í•˜ê² ìŠµë‹ˆë‹¤:"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<div class=\"admonition tip\">\n     <p class=\"admonition-title\">ë” ë‚˜ì€ ë””ë²„ê¹…ì„ ìœ„í•œ <a href=\"https://smith.langchain.com\">LangSmith</a> ì„¤ì •</p>\n     <p style=\"padding-top: 5px;\">\n         LangSmithì— ê°€ì…í•˜ì—¬ ë¬¸ì œë¥¼ ë¹ ë¥´ê²Œ ë°œê²¬í•˜ê³  LangGraph í”„ë¡œì íŠ¸ì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ì„¸ìš”. LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ LangGraphë¡œ êµ¬ì¶•í•œ LLM ì•±ì„ ë””ë²„ê·¸, í…ŒìŠ¤íŠ¸ ë° ëª¨ë‹ˆí„°ë§í•˜ê¸° ìœ„í•´ ì¶”ì  ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ â€” ì‹œì‘í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ë ¤ë©´ <a href=\"https://docs.smith.langchain.com\">ë¬¸ì„œ</a>ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. \n     </p>\n </div>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ReAct ì—ì´ì „íŠ¸ ìƒì„±\n\nì´ì œ í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í–ˆìœ¼ë¯€ë¡œ ReAct ì—ì´ì „íŠ¸ë¥¼ ì½”ë”©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n\n### ê·¸ë˜í”„ ìƒíƒœ ì •ì˜\n\nì´ ì˜ˆì œì—ì„œëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸ ReAct ìƒíƒœë¥¼ ì •ì˜í•  ê²ƒì´ë©°, ì´ëŠ” ë©”ì‹œì§€ ëª©ë¡ë§Œ í¬í•¨í•©ë‹ˆë‹¤.\n\níŠ¹ì • ì‚¬ìš© ì‚¬ë¡€ì— ëŒ€í•´ì„œëŠ” í•„ìš”í•œ ë‹¤ë¥¸ ìƒíƒœ í‚¤ë¥¼ ììœ ë¡­ê²Œ ì¶”ê°€í•˜ì„¸ìš”."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from typing import (\n    Annotated,\n    Sequence,\n    TypedDict,\n)\nfrom langchain_core.messages import BaseMessage\nfrom langgraph.graph.message import add_messages\n\n\nclass AgentState(TypedDict):\n    \"\"\"ì—ì´ì „íŠ¸ì˜ ìƒíƒœì…ë‹ˆë‹¤.\"\"\"\n\n    # add_messagesëŠ” reducerì…ë‹ˆë‹¤\n    # https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers ì°¸ì¡°\n    messages: Annotated[Sequence[BaseMessage], add_messages]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ëª¨ë¸ ë° ë„êµ¬ ì •ì˜\n\në‹¤ìŒìœ¼ë¡œ ì˜ˆì œì— ì‚¬ìš©í•  ë„êµ¬ì™€ ëª¨ë¸ì„ ì •ì˜í•˜ê² ìŠµë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from langchain_openai import ChatOpenAI\nfrom langchain_core.tools import tool\n\nmodel = ChatOpenAI(model=\"gpt-4o-mini\")\n\n\n@tool\ndef get_weather(location: str):\n    \"\"\"íŠ¹ì • ìœ„ì¹˜ì˜ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ í˜¸ì¶œí•©ë‹ˆë‹¤.\"\"\"\n    # ì´ê²ƒì€ ì‹¤ì œ êµ¬í˜„ì„ ìœ„í•œ í”Œë ˆì´ìŠ¤í™€ë”ì…ë‹ˆë‹¤\n    # í•˜ì§€ë§Œ LLMì—ê²ŒëŠ” ì•Œë¦¬ì§€ ë§ˆì„¸ìš” ğŸ˜Š\n    if any([city in location.lower() for city in [\"sf\", \"san francisco\"]]):\n        return \"It's sunny in San Francisco, but you better look out if you're a Gemini ğŸ˜ˆ.\"\n    else:\n        return f\"I am not sure what the weather is in {location}\"\n\n\ntools = [get_weather]\n\nmodel = model.bind_tools(tools)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ë…¸ë“œ ë° ì—£ì§€ ì •ì˜\n\në‹¤ìŒìœ¼ë¡œ ë…¸ë“œì™€ ì—£ì§€ë¥¼ ì •ì˜í•˜ê² ìŠµë‹ˆë‹¤. ê¸°ë³¸ ReAct ì—ì´ì „íŠ¸ì—ëŠ” ëª¨ë¸ í˜¸ì¶œìš© ë…¸ë“œì™€ ë„êµ¬ ì‚¬ìš©ìš© ë…¸ë“œ ë‘ ê°œë§Œ ìˆì§€ë§Œ, ì‚¬ìš© ì‚¬ë¡€ì— ë” ì˜ ë§ë„ë¡ ì´ ê¸°ë³¸ êµ¬ì¡°ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ ì •ì˜í•˜ëŠ” ë„êµ¬ ë…¸ë“œëŠ” ì‚¬ì „ êµ¬ì¶•ëœ [`ToolNode`](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/)ì˜ ë‹¨ìˆœí™”ëœ ë²„ì „ìœ¼ë¡œ, ëª‡ ê°€ì§€ ì¶”ê°€ ê¸°ëŠ¥ì´ ìˆìŠµë‹ˆë‹¤.\n\n[êµ¬ì¡°í™”ëœ ì¶œë ¥ ì¶”ê°€](https://langchain-ai.github.io/langgraph/how-tos/react-agent-structured-output/)ë¥¼ ìœ„í•œ ë…¸ë“œ ë˜ëŠ” ì¼ë¶€ ì™¸ë¶€ ì‘ì—…(ì´ë©”ì¼ ë³´ë‚´ê¸°, ìº˜ë¦°ë” ì´ë²¤íŠ¸ ì¶”ê°€ ë“±)ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ë…¸ë“œë¥¼ ì¶”ê°€í•˜ê³  ì‹¶ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. `call_model` ë…¸ë“œê°€ ì‘ë™í•˜ëŠ” ë°©ì‹ê³¼ `should_continue`ê°€ ë„êµ¬ë¥¼ í˜¸ì¶œí• ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” ë°©ì‹ì„ ë³€ê²½í•˜ê³  ì‹¶ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤ - ê°€ëŠ¥ì„±ì€ ë¬´ê¶ë¬´ì§„í•˜ë©° LangGraphëŠ” íŠ¹ì • ì‚¬ìš© ì‚¬ë¡€ì— ë§ê²Œ ì´ ê¸°ë³¸ êµ¬ì¡°ë¥¼ ì‰½ê²Œ ì‚¬ìš©ì ì •ì˜í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nfrom langchain_core.messages import ToolMessage, SystemMessage\nfrom langchain_core.runnables import RunnableConfig\n\ntools_by_name = {tool.name: tool for tool in tools}\n\n\n# ë„êµ¬ ë…¸ë“œ ì •ì˜\ndef tool_node(state: AgentState):\n    outputs = []\n    for tool_call in state[\"messages\"][-1].tool_calls:\n        tool_result = tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n        outputs.append(\n            ToolMessage(\n                content=json.dumps(tool_result),\n                name=tool_call[\"name\"],\n                tool_call_id=tool_call[\"id\"],\n            )\n        )\n    return {\"messages\": outputs}\n\n\n# ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” ë…¸ë“œ ì •ì˜\ndef call_model(\n    state: AgentState,\n    config: RunnableConfig,\n):\n    # ì´ê²ƒì€ 'prompt' ë§¤ê°œë³€ìˆ˜ë¡œ create_react_agentë¥¼ ì‚¬ìš©ì ì •ì˜í•˜ëŠ” ê²ƒê³¼ ìœ ì‚¬í•˜ì§€ë§Œ ë” ìœ ì—°í•©ë‹ˆë‹¤\n    system_prompt = SystemMessage(\n        \"You are a helpful AI assistant, please respond to the users query to the best of your ability!\"\n    )\n    response = model.invoke([system_prompt] + state[\"messages\"], config)\n    # ê¸°ì¡´ ëª©ë¡ì— ì¶”ê°€ë  ê²ƒì´ë¯€ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤\n    return {\"messages\": [response]}\n\n\n# ê³„ì†í• ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” ì¡°ê±´ë¶€ ì—£ì§€ ì •ì˜\ndef should_continue(state: AgentState):\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # í•¨ìˆ˜ í˜¸ì¶œì´ ì—†ìœ¼ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤\n    if not last_message.tool_calls:\n        return \"end\"\n    # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ê³„ì†í•©ë‹ˆë‹¤\n    else:\n        return \"continue\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ê·¸ë˜í”„ ì •ì˜\n\nì´ì œ ëª¨ë“  ë…¸ë“œì™€ ì—£ì§€ë¥¼ ì •ì˜í–ˆìœ¼ë¯€ë¡œ ê·¸ë˜í”„ë¥¼ ì •ì˜í•˜ê³  ì»´íŒŒì¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ë§ì€ ë…¸ë“œë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì—£ì§€ë¥¼ ì¶”ê°€í•œ ê²½ìš° íŠ¹ì • ì‚¬ìš© ì‚¬ë¡€ì— ë§ê²Œ ì´ë¥¼ í¸ì§‘í•´ì•¼ í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from langgraph.graph import StateGraph, END\n\n# ìƒˆ ê·¸ë˜í”„ ì •ì˜\nworkflow = StateGraph(AgentState)\n\n# ìˆœí™˜í•  ë‘ ê°œì˜ ë…¸ë“œ ì •ì˜\nworkflow.add_node(\"agent\", call_model)\nworkflow.add_node(\"tools\", tool_node)\n\n# ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ë¥¼ `agent`ë¡œ ì„¤ì •\n# ì´ê²ƒì€ ì´ ë…¸ë“œê°€ ì²« ë²ˆì§¸ë¡œ í˜¸ì¶œëœë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤\nworkflow.set_entry_point(\"agent\")\n\n# ì´ì œ ì¡°ê±´ë¶€ ì—£ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤\nworkflow.add_conditional_edges(\n    # ë¨¼ì € ì‹œì‘ ë…¸ë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤. `agent`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n    # ì´ê²ƒì€ `agent` ë…¸ë“œê°€ í˜¸ì¶œëœ í›„ ì·¨í•˜ëŠ” ì—£ì§€ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n    \"agent\",\n    # ë‹¤ìŒìœ¼ë¡œ ì–´ëŠ ë…¸ë“œê°€ ë‹¤ìŒì— í˜¸ì¶œë ì§€ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\n    should_continue,\n    # ë§ˆì§€ë§‰ìœ¼ë¡œ ë§¤í•‘ì„ ì „ë‹¬í•©ë‹ˆë‹¤.\n    # í‚¤ëŠ” ë¬¸ìì—´ì´ê³  ê°’ì€ ë‹¤ë¥¸ ë…¸ë“œì…ë‹ˆë‹¤.\n    # ENDëŠ” ê·¸ë˜í”„ê°€ ì¢…ë£Œë˜ì–´ì•¼ í•¨ì„ ë‚˜íƒ€ë‚´ëŠ” íŠ¹ìˆ˜ ë…¸ë“œì…ë‹ˆë‹¤.\n    # ì¼ì–´ë‚˜ëŠ” ì¼ì€ `should_continue`ë¥¼ í˜¸ì¶œí•˜ê³  ê·¸ ì¶œë ¥ì´\n    # ì´ ë§¤í•‘ì˜ í‚¤ì™€ ì¼ì¹˜ë©ë‹ˆë‹¤.\n    # ì–´ë–¤ ê²ƒê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ì— ë”°ë¼ í•´ë‹¹ ë…¸ë“œê°€ í˜¸ì¶œë©ë‹ˆë‹¤.\n    {\n        # `tools`ì´ë©´ ë„êµ¬ ë…¸ë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n        \"continue\": \"tools\",\n        # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤.\n        \"end\": END,\n    },\n)\n\n# ì´ì œ `tools`ì—ì„œ `agent`ë¡œ ì¼ë°˜ ì—£ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n# ì´ê²ƒì€ `tools`ê°€ í˜¸ì¶œëœ í›„ `agent` ë…¸ë“œê°€ ë‹¤ìŒì— í˜¸ì¶œëœë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\nworkflow.add_edge(\"tools\", \"agent\")\n\n# ì´ì œ ê·¸ë˜í”„ë¥¼ ì»´íŒŒì¼í•˜ê³  ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\ngraph = workflow.compile()\n\nfrom IPython.display import Image, display\n\ntry:\n    display(Image(graph.get_graph().draw_mermaid_png()))\nexcept Exception:\n    # ì´ê²ƒì€ ëª‡ ê°€ì§€ ì¶”ê°€ ì¢…ì†ì„±ì´ í•„ìš”í•˜ë©° ì„ íƒ ì‚¬í•­ì…ë‹ˆë‹¤\n    pass"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ReAct ì—ì´ì „íŠ¸ ì‚¬ìš©\n\nì´ì œ React ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ì—ˆìœ¼ë¯€ë¡œ ì‹¤ì œë¡œ í…ŒìŠ¤íŠ¸í•´ ë´…ì‹œë‹¤!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ìŠ¤íŠ¸ë¦¼ì„ ê¹”ë”í•˜ê²Œ í¬ë§·í•˜ê¸° ìœ„í•œ í—¬í¼ í•¨ìˆ˜\ndef print_stream(stream):\n    for s in stream:\n        message = s[\"messages\"][-1]\n        if isinstance(message, tuple):\n            print(message)\n        else:\n            message.pretty_print()\n\n\ninputs = {\"messages\": [(\"user\", \"what is the weather in sf\")]}\nprint_stream(graph.stream(inputs, stream_mode=\"values\"))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "ì™„ë²½í•©ë‹ˆë‹¤! ê·¸ë˜í”„ê°€ `get_weather` ë„êµ¬ë¥¼ ì˜¬ë°”ë¥´ê²Œ í˜¸ì¶œí•˜ê³  ë„êµ¬ì—ì„œ ì •ë³´ë¥¼ ë°›ì€ í›„ ì‚¬ìš©ìì—ê²Œ ì‘ë‹µí•©ë‹ˆë‹¤."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}