{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "100c0c81-6a9f-4ba1-b1a8-42aae82b7172",
   "metadata": {},
   "source": "# LangGraph(함수형 API)를 AutoGen, CrewAI 및 기타 프레임워크와 통합하는 방법\n\nLangGraph는 에이전틱 및 멀티 에이전트 애플리케이션을 구축하기 위한 프레임워크입니다. LangGraph는 다른 에이전트 프레임워크와 쉽게 통합할 수 있습니다.\n\nLangGraph를 다른 에이전트 프레임워크와 통합하려는 주요 이유:\n\n- 개별 에이전트가 다른 프레임워크로 구축된 [멀티 에이전트 시스템](../../concepts/multi_agent) 생성\n- LangGraph를 활용하여 [지속성](../../concepts/persistence), [스트리밍](../../concepts/streaming), [단기 및 장기 메모리](../../concepts/memory) 등과 같은 기능 추가\n\n다른 프레임워크의 에이전트를 통합하는 가장 간단한 방법은 LangGraph [노드](../../concepts/low_level/#nodes) 내에서 해당 에이전트를 호출하는 것입니다:\n\n```python\nimport autogen\nfrom langgraph.func import entrypoint, task\n\nautogen_agent = autogen.AssistantAgent(name=\"assistant\", ...)\nuser_proxy = autogen.UserProxyAgent(name=\"user_proxy\", ...)\n\n@task\ndef call_autogen_agent(messages):\n    response = user_proxy.initiate_chat(\n        autogen_agent,\n        message=messages[-1],\n        ...\n    )\n    ...\n\n\n@entrypoint()\ndef workflow(messages):\n    response = call_autogen_agent(messages).result()\n    return response\n\n\nworkflow.invoke(\n    [\n        {\n            \"role\": \"user\",\n            \"content\": \"Find numbers between 10 and 30 in fibonacci sequence\",\n        }\n    ]\n)\n```\n\n이 가이드에서는 AutoGen과 통합되는 LangGraph 챗봇을 구축하는 방법을 보여주지만 다른 프레임워크에도 동일한 접근 방식을 따를 수 있습니다."
  },
  {
   "cell_type": "markdown",
   "id": "b189ceb2-132b-4c7b-81b4-c7b8b062f833",
   "metadata": {},
   "source": "## 설정"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62417d3a-94f9-4a52-9962-12639d714966",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install autogen langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d46da41d-0a71-4654-aec8-9e6ad8765236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1926bbc3-6b06-41e0-9604-860a2bbf8fa3",
   "metadata": {},
   "source": "## AutoGen 에이전트 정의\n\n여기서 AutoGen 에이전트를 정의합니다. [여기](https://github.com/microsoft/autogen/blob/0.2/notebook/agentchat_web_info.ipynb)의 공식 튜토리얼에서 수정했습니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524de117-ff09-4b26-bfe8-a9f85a46ffd5",
   "metadata": {},
   "outputs": [],
   "source": "import autogen\nimport os\n\nconfig_list = [{\"model\": \"gpt-4o\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]\n\nllm_config = {\n    \"timeout\": 600,\n    \"cache_seed\": 42,\n    \"config_list\": config_list,\n    \"temperature\": 0,\n}\n\nautogen_agent = autogen.AssistantAgent(\n    name=\"assistant\",\n    llm_config=llm_config,\n)\n\nuser_proxy = autogen.UserProxyAgent(\n    name=\"user_proxy\",\n    human_input_mode=\"NEVER\",\n    max_consecutive_auto_reply=10,\n    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n    code_execution_config={\n        \"work_dir\": \"web\",\n        \"use_docker\": False,\n    },  # docker를 사용할 수 있는 경우 생성된 코드를 실행하려면 use_docker=True로 설정하세요. docker를 사용하는 것이 생성된 코드를 직접 실행하는 것보다 안전합니다.\n    llm_config=llm_config,\n    system_message=\"Reply TERMINATE if the task has been solved at full satisfaction. Otherwise, reply CONTINUE, or the reason why the task is not solved yet.\",\n)"
  },
  {
   "cell_type": "markdown",
   "id": "8aa858e2-4acb-4f75-be20-b9ccbbcb5073",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc478f5-4a35-43f8-bf59-9cb71289cd00",
   "metadata": {},
   "source": "## 워크플로우 생성\n\n이제 AutoGen 에이전트를 호출하는 LangGraph 챗봇 그래프를 만들겠습니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d129e4e1-3766-429a-b806-cde3d8bc0469",
   "metadata": {},
   "outputs": [],
   "source": "from langchain_core.messages import convert_to_openai_messages, BaseMessage\nfrom langgraph.func import entrypoint, task\nfrom langgraph.graph import add_messages\nfrom langgraph.checkpoint.memory import InMemorySaver\n\n\n@task\ndef call_autogen_agent(messages: list[BaseMessage]):\n    # openai 스타일 메시지로 변환\n    messages = convert_to_openai_messages(messages)\n    response = user_proxy.initiate_chat(\n        autogen_agent,\n        message=messages[-1],\n        # 이전 메시지 기록을 컨텍스트로 전달\n        carryover=messages[:-1],\n    )\n    # 에이전트로부터 최종 응답을 가져옵니다\n    content = response.chat_history[-1][\"content\"]\n    return {\"role\": \"assistant\", \"content\": content}\n\n\n# 대화 기록을 저장하기 위한 단기 메모리 추가\ncheckpointer = InMemorySaver()\n\n\n@entrypoint(checkpointer=checkpointer)\ndef workflow(messages: list[BaseMessage], previous: list[BaseMessage]):\n    messages = add_messages(previous or [], messages)\n    response = call_autogen_agent(messages).result()\n    return entrypoint.final(value=response, save=add_messages(messages, response))"
  },
  {
   "cell_type": "markdown",
   "id": "23d629c3-1d6b-40af-adf6-915e15657566",
   "metadata": {},
   "source": "## 그래프 실행\n\n이제 그래프를 실행할 수 있습니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a279b667-0f5d-4008-8d43-c806a3f379c4",
   "metadata": {},
   "outputs": [],
   "source": "# 향후 상호 작용을 위해 에이전트 출력을 유지하려면 스레드 ID를 전달합니다\n# highlight-next-line\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\n\nfor chunk in workflow.stream(\n    [\n        {\n            \"role\": \"user\",\n            \"content\": \"Find numbers between 10 and 30 in fibonacci sequence\",\n        }\n    ],\n    # highlight-next-line\n    config,\n):\n    print(chunk)"
  },
  {
   "cell_type": "markdown",
   "id": "c6cd57b4-d4ee-49f6-be12-318613849669",
   "metadata": {},
   "source": "LangGraph의 [지속성](https://langchain-ai.github.io/langgraph/concepts/persistence/) 기능을 활용하고 있으므로 이제 동일한 스레드 ID를 사용하여 대화를 계속할 수 있습니다 -- LangGraph는 자동으로 이전 기록을 AutoGen 에이전트에 전달합니다:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68811a7-962e-4fe3-9f45-9b99ebbe04e7",
   "metadata": {},
   "outputs": [],
   "source": "for chunk in workflow.stream(\n    [\n        {\n            \"role\": \"user\",\n            \"content\": \"Multiply the last number by 3\",\n        }\n    ],\n    # highlight-next-line\n    config,\n):\n    print(chunk)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}