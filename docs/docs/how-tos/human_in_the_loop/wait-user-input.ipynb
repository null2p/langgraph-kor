{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51466c8d-8ce4-4b3d-be4e-18fdbeda5f53",
   "metadata": {},
   "source": "# `interrupt`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë‹¤ë¦¬ëŠ” ë°©ë²•\n\n!!! tip \"í•„ìˆ˜ ì¡°ê±´\"\n\n    ì´ ê°€ì´ë“œëŠ” ë‹¤ìŒ ê°œë…ì— ëŒ€í•œ ìµìˆ™í•¨ì„ ê°€ì •í•©ë‹ˆë‹¤:\n\n    * [Human-in-the-loop](../../../concepts/human_in_the_loop)\n    * [LangGraph ìš©ì–´ì§‘](../../../concepts/low_level)\n    \n\n**Human-in-the-loop (HIL)** ìƒí˜¸ ì‘ìš©ì€ [ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#human-in-the-loop)ì— ì¤‘ìš”í•©ë‹ˆë‹¤. ì‚¬ëŒì˜ ì…ë ¥ì„ ê¸°ë‹¤ë¦¬ëŠ” ê²ƒì€ ì¼ë°˜ì ì¸ HIL ìƒí˜¸ ì‘ìš© íŒ¨í„´ìœ¼ë¡œ, ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©ìì—ê²Œ ëª…í™•í™” ì§ˆë¬¸ì„ í•˜ê³  ì§„í–‰í•˜ê¸° ì „ì— ì…ë ¥ì„ ê¸°ë‹¤ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nLangGraphì—ì„œ [`interrupt()`][langgraph.types.interrupt] í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `interrupt`ë¥¼ ì‚¬ìš©í•˜ë©´ ê·¸ë˜í”„ ì‹¤í–‰ì„ ì¤‘ì§€í•˜ì—¬ ì‚¬ìš©ìë¡œë¶€í„° ì…ë ¥ì„ ìˆ˜ì§‘í•˜ê³  ìˆ˜ì§‘ëœ ì…ë ¥ìœ¼ë¡œ ì‹¤í–‰ì„ ê³„ì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
  },
  {
   "cell_type": "markdown",
   "id": "7cbd446a-808f-4394-be92-d45ab818953c",
   "metadata": {},
   "source": "## ì„¤ì •\n\në¨¼ì € í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4ce0ba-7596-4e5f-8bf8-0b0bd6e62833",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abe11f4-62ed-4dc4-8875-3db21e260d1d",
   "metadata": {},
   "source": "ë‹¤ìŒìœ¼ë¡œ Anthropic ë°/ë˜ëŠ” OpenAI(ì‚¬ìš©í•  LLM)ì— ëŒ€í•œ API í‚¤ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903a1cf-2977-4e2d-ad7d-8b3946821d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ed46a8-effe-4596-b0e1-a6a29ee16f5c",
   "metadata": {},
   "source": "<div class=\"admonition tip\">\n    <p class=\"admonition-title\">LangGraph ê°œë°œì„ ìœ„í•œ <a href=\"https://smith.langchain.com\">LangSmith</a> ì„¤ì •</p>\n    <p style=\"padding-top: 5px;\">\n        LangSmithì— ê°€ì…í•˜ì—¬ ë¬¸ì œë¥¼ ë¹ ë¥´ê²Œ ë°œê²¬í•˜ê³  LangGraph í”„ë¡œì íŠ¸ì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ì„¸ìš”. LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ LangGraphë¡œ êµ¬ì¶•í•œ LLM ì•±ì„ ë””ë²„ê·¸, í…ŒìŠ¤íŠ¸ ë° ëª¨ë‹ˆí„°ë§í•˜ê¸° ìœ„í•´ ì¶”ì  ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ â€” ì‹œì‘í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ë ¤ë©´ <a href=\"https://docs.smith.langchain.com\">ì—¬ê¸°</a>ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. \n    </p>\n</div>"
  },
  {
   "cell_type": "markdown",
   "id": "e6cf1fad-5ab6-49c5-b0c8-15a1b6e8cf21",
   "metadata": {},
   "source": "## ê°„ë‹¨í•œ ì‚¬ìš©ë²•\n\nì‚¬ëŒì˜ í”¼ë“œë°±ì„ ì‚¬ìš©í•˜ëŠ” ê¸°ë³¸ ì˜ˆì œë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ ì ‘ê·¼ ë°©ì‹ì€ ì‚¬ìš©ì ì…ë ¥ì„ ìˆ˜ì§‘í•˜ë„ë¡ íŠ¹ë³„íˆ ì„¤ê³„ëœ ë…¸ë“œ **`human_feedback`**ë¥¼ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê·¸ë˜í”„ì˜ íŠ¹ì • ì„ íƒëœ ì§€ì ì—ì„œ í”¼ë“œë°±ì„ ìˆ˜ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\në‹¨ê³„:\n\n1. **`human_feedback`** ë…¸ë“œ ë‚´ë¶€ì—ì„œ **`interrupt()`**ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n2. ì´ ë…¸ë“œê¹Œì§€ ê·¸ë˜í”„ì˜ ìƒíƒœë¥¼ ì €ì¥í•˜ê¸° ìœ„í•´ **[ì²´í¬í¬ì¸í„°](https://langchain-ai.github.io/langgraph/concepts/low_level/#checkpointer)**ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n3. **`Command(resume=...)`**ë¥¼ ì‚¬ìš©í•˜ì—¬ ìš”ì²­ëœ ê°’ì„ **`human_feedback`** ë…¸ë“œì— ì œê³µí•˜ê³  ì‹¤í–‰ì„ ì¬ê°œí•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eae42d-be32-48da-8d0a-ab64471657d9",
   "metadata": {},
   "outputs": [],
   "source": "from typing_extensions import TypedDict\nfrom langgraph.graph import StateGraph, START, END\n\n# highlight-next-line\nfrom langgraph.types import Command, interrupt\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom IPython.display import Image, display\n\n\nclass State(TypedDict):\n    input: str\n    user_feedback: str\n\n\ndef step_1(state):\n    print(\"---Step 1---\")\n    pass\n\n\ndef human_feedback(state):\n    print(\"---human_feedback---\")\n    # highlight-next-line\n    feedback = interrupt(\"Please provide feedback:\")\n    return {\"user_feedback\": feedback}\n\n\ndef step_3(state):\n    print(\"---Step 3---\")\n    pass\n\n\nbuilder = StateGraph(State)\nbuilder.add_node(\"step_1\", step_1)\nbuilder.add_node(\"human_feedback\", human_feedback)\nbuilder.add_node(\"step_3\", step_3)\nbuilder.add_edge(START, \"step_1\")\nbuilder.add_edge(\"step_1\", \"human_feedback\")\nbuilder.add_edge(\"human_feedback\", \"step_3\")\nbuilder.add_edge(\"step_3\", END)\n\n# ë©”ëª¨ë¦¬ ì„¤ì •\nmemory = InMemorySaver()\n\n# ì¶”ê°€\ngraph = builder.compile(checkpointer=memory)\n\n# ë³´ê¸°\ndisplay(Image(graph.get_graph().draw_mermaid_png()))"
  },
  {
   "cell_type": "markdown",
   "id": "ce0fe2bc-86fc-465f-956c-729805d50404",
   "metadata": {},
   "source": "`human_feedback`ì˜ `interrupt()`ê¹Œì§€ ì‹¤í–‰í•©ë‹ˆë‹¤:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e7d47-e7c9-4217-b72c-08394a2c4d3e",
   "metadata": {},
   "outputs": [],
   "source": "# ì…ë ¥\ninitial_input = {\"input\": \"hello world\"}\n\n# ìŠ¤ë ˆë“œ\nthread = {\"configurable\": {\"thread_id\": \"1\"}}\n\n# ì²« ë²ˆì§¸ ì¤‘ë‹¨ê¹Œì§€ ê·¸ë˜í”„ ì‹¤í–‰\nfor event in graph.stream(initial_input, thread, stream_mode=\"updates\"):\n    print(event)\n    print(\"\\n\")"
  },
  {
   "cell_type": "markdown",
   "id": "28a7d545-ab19-4800-985b-62837d060809",
   "metadata": {},
   "source": "ì´ì œ ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ê·¸ë˜í”„ ìƒíƒœë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca588f-e8d8-416b-aba7-0f3ae5e51598",
   "metadata": {},
   "outputs": [],
   "source": "# ê·¸ë˜í”„ ì‹¤í–‰ ê³„ì†\nfor event in graph.stream(\n    # highlight-next-line\n    Command(resume=\"go to step 3!\"),\n    thread,\n    stream_mode=\"updates\",\n):\n    print(event)\n    print(\"\\n\")"
  },
  {
   "cell_type": "markdown",
   "id": "a75a1060-47aa-4cc6-8c41-e6ba2e9d7923",
   "metadata": {},
   "source": "í”¼ë“œë°±ì´ ìƒíƒœì— ì¶”ê°€ëœ ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ - "
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b83e5ca-8497-43ca-bff7-7203e654c4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hello world', 'user_feedback': 'go to step 3!'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(thread).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22b9598-7ce4-4d16-b932-bba2bc2803ec",
   "metadata": {},
   "source": "## ì—ì´ì „íŠ¸\n\n[ì—ì´ì „íŠ¸](../../../concepts/agentic_concepts) ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì‚¬ìš©ì í”¼ë“œë°±ì„ ê¸°ë‹¤ë¦¬ëŠ” ê²ƒì€ ëª…í™•í™” ì§ˆë¬¸ì„ í•˜ëŠ” ë° íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤. ì´ë¥¼ ì„¤ëª…í•˜ê¸° ìœ„í•´ [ë„êµ¬ í˜¸ì¶œ](https://python.langchain.com/docs/concepts/tool_calling/)ì´ ê°€ëŠ¥í•œ ê°„ë‹¨í•œ [ReAct ìŠ¤íƒ€ì¼ ì—ì´ì „íŠ¸](../../../concepts/agentic_concepts#react-implementation)ë¥¼ ë§Œë“¤ ê²ƒì…ë‹ˆë‹¤.\n\nì´ ì˜ˆì œì—ì„œëŠ” Anthropicì˜ ì±„íŒ… ëª¨ë¸ê³¼ **ëª¨ì˜ ë„êµ¬**(ìˆœì „íˆ ì‹œì—° ëª©ì )ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "markdown",
   "id": "01789855-b769-426d-a329-3cdb29684df8",
   "metadata": {},
   "source": "<div class=\"admonition note\">\n    <p class=\"admonition-title\">LangChainê³¼ í•¨ê»˜ Pydantic ì‚¬ìš©í•˜ê¸°</p>\n    <p>\n        ì´ ë…¸íŠ¸ë¶ì€ Pydantic v2 <code>BaseModel</code>ì„ ì‚¬ìš©í•˜ë©°, <code>langchain-core >= 0.3</code>ì´ í•„ìš”í•©ë‹ˆë‹¤. <code>langchain-core < 0.3</code>ì„ ì‚¬ìš©í•˜ë©´ Pydantic v1 ë° v2 <code>BaseModels</code>ì˜ í˜¼í•©ìœ¼ë¡œ ì¸í•´ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n    </p>\n</div>  "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5319e01",
   "metadata": {},
   "outputs": [],
   "source": "# ìƒíƒœ ì„¤ì •\nfrom langgraph.graph import MessagesState, START\n\n# ë„êµ¬ ì„¤ì •\n# í•˜ë‚˜ì˜ ì‹¤ì œ ë„êµ¬ - ê²€ìƒ‰ ë„êµ¬ê°€ ìˆìŠµë‹ˆë‹¤\n# ë˜í•œ í•˜ë‚˜ì˜ \"ê°€ì§œ\" ë„êµ¬ - \"ask_human\" ë„êµ¬ë„ ìˆìŠµë‹ˆë‹¤\n# ì—¬ê¸°ì„œ ì‹¤ì œ ë„êµ¬ë¥¼ ì •ì˜í•©ë‹ˆë‹¤\nfrom langchain_core.tools import tool\nfrom langgraph.prebuilt import ToolNode\n\n\n@tool\ndef search(query: str):\n    \"\"\"ì›¹ì„ ì„œí•‘í•˜ê¸° ìœ„í•´ í˜¸ì¶œí•©ë‹ˆë‹¤.\"\"\"\n    # ì´ê²ƒì€ ì‹¤ì œ êµ¬í˜„ì„ ìœ„í•œ í”Œë ˆì´ìŠ¤í™€ë”ì…ë‹ˆë‹¤\n    # í•˜ì§€ë§Œ LLMì—ê²ŒëŠ” ì•Œë¦¬ì§€ ë§ˆì„¸ìš” ğŸ˜Š\n    return f\"I looked up: {query}. Result: It's sunny in San Francisco, but you better look out if you're a Gemini ğŸ˜ˆ.\"\n\n\ntools = [search]\ntool_node = ToolNode(tools)\n\n# ëª¨ë¸ ì„¤ì •\nfrom langchain_anthropic import ChatAnthropic\n\nmodel = ChatAnthropic(model=\"claude-3-5-sonnet-latest\")\n\nfrom pydantic import BaseModel\n\n\n# ëª¨ë“  ë„êµ¬ë¥¼ ëª¨ë¸ì— \"ë°”ì¸ë”©\"í•  ê²ƒì…ë‹ˆë‹¤\n# ìœ„ì˜ ì‹¤ì œ ë„êµ¬ê°€ ìˆì§€ë§Œ ì‚¬ëŒì—ê²Œ ë¬»ëŠ” ëª¨ì˜ ë„êµ¬ë„ í•„ìš”í•©ë‹ˆë‹¤\n# `bind_tools`ê°€ ë„êµ¬ë¿ë§Œ ì•„ë‹ˆë¼ ë„êµ¬ ì •ì˜ë„ ë°›ìœ¼ë¯€ë¡œ,\n# `ask_human`ì— ëŒ€í•œ ë„êµ¬ ì •ì˜ë¥¼ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\nclass AskHuman(BaseModel):\n    \"\"\"ì‚¬ëŒì—ê²Œ ì§ˆë¬¸í•˜ê¸°\"\"\"\n\n    question: str\n\n\nmodel = model.bind_tools(tools + [AskHuman])\n\n# ë…¸ë“œ ë° ì¡°ê±´ë¶€ ì—£ì§€ ì •ì˜\n\n\n# ê³„ì†í• ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ ì •ì˜\ndef should_continue(state):\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # í•¨ìˆ˜ í˜¸ì¶œì´ ì—†ìœ¼ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤\n    if not last_message.tool_calls:\n        return END\n    # ë„êµ¬ í˜¸ì¶œì´ Humanì—ê²Œ ë¬»ëŠ” ê²ƒì´ë©´ í•´ë‹¹ ë…¸ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤\n    # ì—¬ê¸°ì— ì¼ë¶€ ì‹œìŠ¤í…œì— Human ì…ë ¥ì´ í•„ìš”í•œ ê²ƒì´ ìˆìŒì„ ì•Œë¦¬ëŠ” ë¡œì§ì„ ì¶”ê°€í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤\n    # ì˜ˆë¥¼ ë“¤ì–´ ìŠ¬ë™ ë©”ì‹œì§€ ì „ì†¡ ë“±\n    elif last_message.tool_calls[0][\"name\"] == \"AskHuman\":\n        return \"ask_human\"\n    # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ê³„ì†í•©ë‹ˆë‹¤\n    else:\n        return \"action\"\n\n\n# ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜ ì •ì˜\ndef call_model(state):\n    messages = state[\"messages\"]\n    response = model.invoke(messages)\n    # ê¸°ì¡´ ëª©ë¡ì— ì¶”ê°€ë  ê²ƒì´ë¯€ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤\n    return {\"messages\": [response]}\n\n\n# ì‚¬ëŒì—ê²Œ ë¬»ëŠ” ê°€ì§œ ë…¸ë“œ ì •ì˜\ndef ask_human(state):\n    tool_call_id = state[\"messages\"][-1].tool_calls[0][\"id\"]\n    ask = AskHuman.model_validate(state[\"messages\"][-1].tool_calls[0][\"args\"])\n    # highlight-next-line\n    location = interrupt(ask.question)\n    tool_message = [{\"tool_call_id\": tool_call_id, \"type\": \"tool\", \"content\": location}]\n    return {\"messages\": tool_message}\n\n\n# ê·¸ë˜í”„ ë¹Œë“œ\n\nfrom langgraph.graph import END, StateGraph\n\n# ìƒˆ ê·¸ë˜í”„ ì •ì˜\nworkflow = StateGraph(MessagesState)\n\n# ìˆœí™˜í•  ì„¸ ê°œì˜ ë…¸ë“œ ì •ì˜\nworkflow.add_node(\"agent\", call_model)\nworkflow.add_node(\"action\", tool_node)\nworkflow.add_node(\"ask_human\", ask_human)\n\n# ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ë¥¼ `agent`ë¡œ ì„¤ì •\n# ì´ê²ƒì€ ì´ ë…¸ë“œê°€ ì²« ë²ˆì§¸ë¡œ í˜¸ì¶œëœë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤\nworkflow.add_edge(START, \"agent\")\n\n# ì´ì œ ì¡°ê±´ë¶€ ì—£ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤\nworkflow.add_conditional_edges(\n    # ë¨¼ì € ì‹œì‘ ë…¸ë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤. `agent`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n    # ì´ê²ƒì€ `agent` ë…¸ë“œê°€ í˜¸ì¶œëœ í›„ ì·¨í•˜ëŠ” ì—£ì§€ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n    \"agent\",\n    # ë‹¤ìŒìœ¼ë¡œ ì–´ëŠ ë…¸ë“œê°€ ë‹¤ìŒì— í˜¸ì¶œë ì§€ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\n    should_continue,\n    path_map=[\"ask_human\", \"action\", END],\n)\n\n# ì´ì œ `tools`ì—ì„œ `agent`ë¡œ ì¼ë°˜ ì—£ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n# ì´ê²ƒì€ `tools`ê°€ í˜¸ì¶œëœ í›„ `agent` ë…¸ë“œê°€ ë‹¤ìŒì— í˜¸ì¶œëœë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\nworkflow.add_edge(\"action\", \"agent\")\n\n# ì‚¬ëŒì˜ ì‘ë‹µì„ ë°›ì€ í›„ ì—ì´ì „íŠ¸ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤\nworkflow.add_edge(\"ask_human\", \"agent\")\n\n# ë©”ëª¨ë¦¬ ì„¤ì •\nfrom langgraph.checkpoint.memory import InMemorySaver\n\nmemory = InMemorySaver()\n\n# ë§ˆì§€ë§‰ìœ¼ë¡œ ì»´íŒŒì¼í•©ë‹ˆë‹¤!\n# ì´ê²ƒì€ LangChain Runnableë¡œ ì»´íŒŒì¼ë©ë‹ˆë‹¤,\n# ì¦‰ ë‹¤ë¥¸ runnableê³¼ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\napp = workflow.compile(checkpointer=memory)\n\ndisplay(Image(app.get_graph().draw_mermaid_png()))"
  },
  {
   "cell_type": "markdown",
   "id": "2a1b56c5-bd61-4192-8bdb-458a1e9f0159",
   "metadata": {},
   "source": "## ì—ì´ì „íŠ¸ì™€ ìƒí˜¸ ì‘ìš©\n\nì´ì œ ì—ì´ì „íŠ¸ì™€ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì–´ë””ì— ìˆëŠ”ì§€ ë¬»ë„ë¡ í•œ ë‹¤ìŒ ë‚ ì”¨ë¥¼ ì•Œë ¤ì£¼ë„ë¡ ìš”ì²­í•´ ë´…ì‹œë‹¤.\n\nì´ê²ƒì€ ë¨¼ì € `ask_human` ë„êµ¬ë¥¼ ì‚¬ìš©í•œ ë‹¤ìŒ ì¼ë°˜ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd140f0-a5a6-4697-8115-322242f197b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ask the user where they are, then look up the weather there\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'll help you with that. Let me first ask the user about their location.\", 'type': 'text'}, {'id': 'toolu_012Z9yyZjvH8xKgMShgwpQZ9', 'input': {'question': 'Where are you located?'}, 'name': 'AskHuman', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  AskHuman (toolu_012Z9yyZjvH8xKgMShgwpQZ9)\n",
      " Call ID: toolu_012Z9yyZjvH8xKgMShgwpQZ9\n",
      "  Args:\n",
      "    question: Where are you located?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in app.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Ask the user where they are, then look up the weather there\",\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "924a30ea-94c0-468e-90fe-47eb9c08584d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ask_human',)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.get_state(config).next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a30c9fb-2a40-45cc-87ba-406c11c9f0cf",
   "metadata": {},
   "source": "ê·¸ë˜í”„ê°€ `ask_human` ë…¸ë“œ ë‚´ë¶€ì—ì„œ ì¤‘ë‹¨ë˜ì—ˆê³  `location`ì´ ì œê³µë˜ê¸°ë¥¼ ê¸°ë‹¤ë¦¬ê³  ìˆëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. `Command(resume=\"<location>\")` ì…ë ¥ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ í˜¸ì¶œí•˜ì—¬ ì´ ê°’ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9f599b5-1a55-406b-a76b-f52b3ca06975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'll help you with that. Let me first ask the user about their location.\", 'type': 'text'}, {'id': 'toolu_012Z9yyZjvH8xKgMShgwpQZ9', 'input': {'question': 'Where are you located?'}, 'name': 'AskHuman', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  AskHuman (toolu_012Z9yyZjvH8xKgMShgwpQZ9)\n",
      " Call ID: toolu_012Z9yyZjvH8xKgMShgwpQZ9\n",
      "  Args:\n",
      "    question: Where are you located?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "san francisco\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Now I'll search for the weather in San Francisco.\", 'type': 'text'}, {'id': 'toolu_01QrWBCDouvBuJPZa4veepLw', 'input': {'query': 'current weather in san francisco'}, 'name': 'search', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  search (toolu_01QrWBCDouvBuJPZa4veepLw)\n",
      " Call ID: toolu_01QrWBCDouvBuJPZa4veepLw\n",
      "  Args:\n",
      "    query: current weather in san francisco\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search\n",
      "\n",
      "I looked up: current weather in san francisco. Result: It's sunny in San Francisco, but you better look out if you're a Gemini ğŸ˜ˆ.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the search results, it's currently sunny in San Francisco. Would you like more specific weather details?\n"
     ]
    }
   ],
   "source": [
    "for event in app.stream(\n",
    "    # highlight-next-line\n",
    "    Command(resume=\"san francisco\"),\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}